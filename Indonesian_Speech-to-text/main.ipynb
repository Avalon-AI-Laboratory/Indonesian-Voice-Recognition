{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><u>Pengembangan Aplikasi <i>Speech-to-text</i> Bahasa Indonesia Dengan Arsitektur Transformer Terutilisasi</u></h2>\n",
    "<b>Dr. Rizka Wakhidatus Sholikah, S.Kom.*</b><br>\n",
    "<i>Departemen Teknologi Informasi, Institut Teknologi Sepuluh Nopember Surabaya</i>\n",
    "\n",
    "<b>Kevin Putra Santoso</b><br>\n",
    "<i>Departemen Teknologi Informasi, Institut Teknologi Sepuluh Nopember Surabaya</i>\n",
    "\n",
    "<b>Mohammad Idris Arif Budiman</b><br>\n",
    "<i>Departemen Teknik Informatika, Institut Teknologi Sepuluh Nopember Surabaya</i>\n",
    "\n",
    "Dalam proyek ini, kami mencoba menerapkan arsitektur Transformer yang terinspirasi dari paper **Attention is All You Need** (oleh Google Brain) dan arsitektur **Whisper** dari OpenAI untuk melakukan Automatic Speech Recognition dalam bahasa Indonesia. Data yang digunakan dalam proyek ini adalah Mozilla Common Voice untuk bahasa Indonesia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import string\n",
    "\n",
    "from models.transformer import Transformer\n",
    "from ops.scheduler import Scheduler\n",
    "from ops.base_functions import conv_char2num, conv_num2char\n",
    "from ops.loss import SmoothCTC_CrossEntropyLoss\n",
    "from ops.data_preprocessor import AudioDataset\n",
    "import warnings\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1  = pd.read_csv('./dataset/common_voice_id/train.tsv', sep='\\t')\n",
    "df2 = pd.read_csv('./dataset/common_voice_id/validated.tsv', sep='\\t')\n",
    "df3 = pd.read_csv('./dataset/common_voice_id/test.tsv', sep='\\t')\n",
    "\n",
    "df1 = df1[['path', 'sentence']]\n",
    "df2 = df2[['path', 'sentence']]\n",
    "df3 = df3[['path', 'sentence']]\n",
    "\n",
    "df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "df = df.drop_duplicates()\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25684, 2)\n",
      "(25684, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df_testing = df\n",
    "print(df_testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_strips(text):\n",
    "    cleaned_text = text.replace('“', '')\n",
    "    cleaned_text = cleaned_text.replace('”', '')\n",
    "    cleaned_text = cleaned_text.replace('‘', '')\n",
    "    cleaned_text = cleaned_text.replace('’', '')\n",
    "    cleaned_text = cleaned_text.replace(',', ' ')\n",
    "    cleaned_text = cleaned_text.replace('-', ' ')\n",
    "    cleaned_text = cleaned_text.replace(\"'\", '')\n",
    "    cleaned_text = cleaned_text.replace(\"—\", '')\n",
    "    cleaned_text = cleaned_text.replace(\"–\", '')\n",
    "    cleaned_text = cleaned_text.replace(\"，\", ' ')\n",
    "    cleaned_text = cleaned_text.replace(\".\", ' ')\n",
    "    cleaned_text = cleaned_text.replace(\"á\", 'a')\n",
    "    cleaned_text = cleaned_text.replace(\"é\", 'e')\n",
    "    cleaned_text = cleaned_text.replace(\"0\", 'nol')\n",
    "    cleaned_text = cleaned_text.replace(\"1\", 'satu')\n",
    "    cleaned_text = cleaned_text.replace(\"2\", 'dua')\n",
    "    cleaned_text = cleaned_text.replace(\"3\", 'tiga')\n",
    "    cleaned_text = cleaned_text.replace(\"4\", 'empat')\n",
    "    cleaned_text = cleaned_text.replace(\"5\", 'lima')\n",
    "    cleaned_text = cleaned_text.replace(\"6\", 'enam')\n",
    "    cleaned_text = cleaned_text.replace(\"7\", 'tujuh')\n",
    "    cleaned_text = cleaned_text.replace(\"8\", 'delapan')\n",
    "    cleaned_text = cleaned_text.replace(\"9\", 'sembilan')\n",
    "    cleaned_text = cleaned_text.replace(\"[\", '')\n",
    "    cleaned_text = cleaned_text.replace(\"]\", '')\n",
    "    cleaned_text = cleaned_text.replace(\"\\\\\", '')\n",
    "    cleaned_text = cleaned_text.replace(\"！\", '')\n",
    "    cleaned_text = cleaned_text.strip(string.punctuation)\n",
    "    return cleaned_text\n",
    "\n",
    "for i in range(len(df_testing['sentence'])):\n",
    "    df_testing['sentence'][i] = df_testing['sentence'][i].lower()\n",
    "    df_testing['sentence'][i] = ' '.join(word.strip(string.punctuation) for word in df_testing['sentence'][i].split())\n",
    "    df_testing['sentence'][i] = ' '.join(remove_strips(word) for word in df_testing['sentence'][i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = []\n",
    "HOME = os.getcwd()\n",
    "for i in range(len(df_testing)):\n",
    "    os.system(f'copy \\\"{HOME}\\\\dataset\\\\common_voice_id\\\\clips\\\\{df_testing[\"path\"][i]}\\\" \\\"{HOME}\\\\dataset\\\\audio_folder\\\\{df_testing[\"path\"][i]}\\\"')\n",
    "    label_list.append(df_testing['sentence'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banyaknya label: 25684\n",
      "Sampel 5 label\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['kemarin saya belajar',\n",
       " 'kamu adalah seorang penjahat',\n",
       " 'saya datang ke jepang pada tanggal lima belas maret tahun ini',\n",
       " 'kamu lucu banget',\n",
       " 'apakah kamu sudah minum obat']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Banyaknya label: {len(label_list)}')\n",
    "print('Sampel 5 label')\n",
    "label_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset = AudioDataset(df_testing, './dataset/audio_folder/')\n",
    "id_error = []\n",
    "\n",
    "for idx in range(len(df_testing)):\n",
    "    try:\n",
    "        testDataset[idx]\n",
    "    except:\n",
    "        id_error.append(idx)\n",
    "\n",
    "df_testing = df_testing.drop(id_error).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sekilas Terkait Data\n",
    "Dataset yang akan kita latih diharapkan memiliki format sebagai berikut.\n",
    "\n",
    "```python\n",
    "[[tensor_1], [transcription_1],\n",
    " [tensor_2], [transcription_2],\n",
    " ...\n",
    " [tensor_n], [transcription_n]]\n",
    "```\n",
    "\n",
    "Untuk itu modul ```Dataset``` oleh PyTorch dapat digunakan untuk membuat dataset ini. Modul ini dipanggil dengan syntax\n",
    "\n",
    "```python\n",
    "from torch.utils.data import Dataset\n",
    "```\n",
    "\n",
    "dengan ukuran batch (batch size) sebesar 64.\n",
    "\n",
    "tensor_i adalah tensor yang memuat matriks Log Mel Spectogram dari sebuah audio. Meninjau ulang bahwa sebuah matriks Log Mel Spectogram memiliki ukuran ```(n_mel, timesteps)``` dengan ```n_mel=64``` dan timesteps bergantung dari audio yang memiliki durasi terpanjang (timesteps tidak sama dengan durasi audio).\n",
    "\n",
    "transcription_i adalah tensor yang memuat transkripsi yang telah di encode menjadi angka dalam dictionary encoder yang ditentukan oleh user (biasa disebut sebagai vocabulary). tensor ini memiliki ukuran ```(1, max_len)``` dimana ```max_len``` adalah transkripsi terpanjang dari sebuah audio. Perlu diingat bahwa panjang transkripsi maksimum akan dibatasi sebesar 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representasi Numerik (dengan padding):\n",
      "[ 2 22  4 28  4  1  5  8 21  4 17 10 14  4 23  1 14  8  1 22  8 14 18 15\n",
      "  4 11  1  7 12  1 19  4 10 12  1 11  4 21 12  3  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Invers: \n",
      "<saya berangkat ke sekolah di pagi hari>\n"
     ]
    }
   ],
   "source": [
    "# Tes conv_char2num dan conv_num2char\n",
    "example_text = 'Saya berangkat ke sekolah di pagi hari'\n",
    "numeric_representation = conv_char2num(example_text)\n",
    "print('Representasi Numerik (dengan padding):')\n",
    "print(numeric_representation)\n",
    "print('Invers: ')\n",
    "print(conv_num2char(numeric_representation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, split_point=0.8):\n",
    "    data_size = len(df)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    split = int(split_point * data_size)\n",
    "    df_train, df_valid = df[:split], df[split:]\n",
    "    df_train\n",
    "    \n",
    "    return df_train, df_valid.reset_index(drop=True)\n",
    "\n",
    "df_train, df_valid = split_data(df_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy train audio data to 'train' folder\n",
    "label_list_train = []\n",
    "\n",
    "for i in range(len(df_train)):\n",
    "    os.system(f'move \\\"{HOME}\\\\dataset\\\\audio_folder\\\\{df_train[\"path\"][i]}\\\" \\\"{HOME}\\\\dataset\\\\audio_folder\\\\train\\\\{df_train[\"path\"][i]}\\\"')\n",
    "    label_list_train.append(df_train['sentence'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy validation audio data to 'valid' folder\n",
    "label_list_valid = []\n",
    "\n",
    "for i in range(len(df_valid)):\n",
    "    os.system(f'move \\\"{HOME}\\\\dataset\\\\audio_folder\\\\{df_valid[\"path\"][i]}\\\" \\\"{HOME}\\\\dataset\\\\audio_folder\\\\valid\\\\{df_valid[\"path\"][i]}\\\"')\n",
    "    label_list_valid.append(df_valid['sentence'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing dan Load Data\n",
    "Untuk melakukan preprocessing data, perangkat alam menjadi faktor utama yang perlu dikonsiderasi. Untuk menghindari crash atau memory overleak, akan lebih baik jika preprocessing dilakukan dengan sistem batch. Dengan kata lain, kita perlu membuat data loader khusus audio lalu menggunakan data loader dengan batch tertentu untuk melatih model kita agar alokasi memori tidak berlebihan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = AudioDataset(df_train, './dataset/audio_folder/train/')\n",
    "valid_dataset = AudioDataset(df_valid, './dataset/audio_folder/valid/')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_error = []\n",
    "\n",
    "for idx in range(len(df_train)):\n",
    "    try:\n",
    "        train_dataset[idx]\n",
    "    except:\n",
    "        id_error.append(idx)\n",
    "\n",
    "df_train = df_train.drop(id_error).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persiapan Model, Optimizer, dan Scheduler Untuk Transformer\n",
    "\n",
    "Dalam percobaan training ini, kami menggunakan jumlah n_embedding sebanyak 192. Angka ini kami tetapkan atas konsiderasi mengenai banyaknya kosakata yang mungkin tersusun dalam bahasa Indonesia. Jumlah attention head, layer feed-forward network, layer encoder, dan layer decoder pun ditetapkan default dengan konfigurasi (4, 400, 8, 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(num_hid = 192,\n",
    "                    num_head = 4,\n",
    "                    num_feed_forward = 400,\n",
    "                    num_layers_enc = 8,\n",
    "                    num_layers_dec = 5).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-5)\n",
    "scheduler = Scheduler(optimizer, steps_per_epoch=len(train_dataloader))\n",
    "ctc_ce_loss = SmoothCTC_CrossEntropyLoss(smoothing = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proses Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from tqdm import tqdm\n",
    "from jiwer import wer\n",
    "import re\n",
    "\n",
    "start_token_id = 2\n",
    "end_token_id = 3\n",
    "\n",
    "def train_step(model, optimizer, batch):\n",
    "    source = batch[0].float().to(device)\n",
    "    target = batch[1].to(device)\n",
    "    dec_input = target[:, :-1]\n",
    "    dec_target = target[:, 1:]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    preds = model([source, dec_input])\n",
    "    loss = ctc_ce_loss(preds, dec_target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return {\"Loss\": loss.item()}\n",
    "\n",
    "def validate(model, validation_set):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in validation_set:\n",
    "            source = batch[0].float().to(device)\n",
    "            target = batch[1].to(device)\n",
    "            dec_input = target[:, :-1]\n",
    "            dec_target = target[:, 1:]\n",
    "            \n",
    "            preds = model([source, dec_input])\n",
    "            loss = ctc_ce_loss(preds, dec_target)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(validation_set)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth 0 =>  <setelah pulang sekolah saya minum teh di kedai kopi bersama teman>\n",
      "Generation 0   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 1 =>  <ini yang terakhir>\n",
      "Generation 1   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 2 =>  <seperti seri berjalan dengan sebelumnya diceritakan oleh kenneth branagh>\n",
      "Generation 2   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 3 =>  <adik laki laki saya berumur sembilan tahun>\n",
      "Generation 3   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 4 =>  <aku mabuk>\n",
      "Generation 4   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 5 =>  <sebuah festival di bulan oktober di alun alun kota>\n",
      "Generation 5   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 6 =>  <lebih baik tinggal di rumah daripada pergi keluar>\n",
      "Generation 6   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 7 =>  <pemancarnya ada di dekat mercier>\n",
      "Generation 7   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 8 =>  <film apa yang ingin kamu tonton>\n",
      "Generation 8   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 9 =>  <tom telah terluka>\n",
      "Generation 9   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 10 =>  <bagaimana dengan wawancara anda>\n",
      "Generation 10   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 11 =>  <mereka memiliki empat putri dan satu putra bersama sama>\n",
      "Generation 11   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 12 =>  <tidak jelas apakah mitologi babilonia dan ibrani ada hubungannya>\n",
      "Generation 12   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 13 =>  <nancy adalah perempuan yang sulit untuk aku dekati>\n",
      "Generation 13   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 14 =>  <aku suka uang tapi uang suka habis>\n",
      "Generation 14   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 15 =>  <abbot membunuh mary>\n",
      "Generation 15   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 16 =>  <saya memesan empat masakan di restoran>\n",
      "Generation 16   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 17 =>  <berapa banyak penerbangan ke boston yang ditawarkan dalam sehari>\n",
      "Generation 17   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 18 =>  <kalau tekan di sini kopinya akan keluar>\n",
      "Generation 18   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 19 =>  <saya akan masak gulai kambing nanti malam>\n",
      "Generation 19   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 20 =>  <seperti dorsey mcgahee juga merupakan finalis heisman>\n",
      "Generation 20   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 21 =>  <kamu sudah sehat kan>\n",
      "Generation 21   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 22 =>  <ini adalah rumah yang dibangun oleh jack>\n",
      "Generation 22   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 23 =>  <bagaimana kamu bisa selalu bersemangat>\n",
      "Generation 23   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 24 =>  <jim mahir dalam bahasa perancis dan jerman>\n",
      "Generation 24   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 25 =>  <apakah orang tuamu setuju kamu menjadi pramugari>\n",
      "Generation 25   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 26 =>  <ia membuka pintu kamar kemudian menyalakan lampu>\n",
      "Generation 26   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 27 =>  <gadis yang berdiri di sana adalah mary>\n",
      "Generation 27   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 28 =>  <aku berikan kamu kataku>\n",
      "Generation 28   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 29 =>  <saya jamin jam ini tidak meleset>\n",
      "Generation 29   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 30 =>  <penjara terkait adalah metropolitan detention center brooklyn>\n",
      "Generation 30   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n",
      "Ground truth 31 =>  <salah satu hobiku membuat bunga palsu>\n",
      "Generation 31   =>  None\n",
      "Ada kesalahan saat menghitung WER\n",
      "-------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Indonesian-Speech-to-text\\main.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Indonesian-Speech-to-text/main.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss[\u001b[39m'\u001b[39m\u001b[39mLoss\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Indonesian-Speech-to-text/main.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m avg_epoch_loss \u001b[39m=\u001b[39m epoch_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(train_dataloader)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Indonesian-Speech-to-text/main.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m validation_loss \u001b[39m=\u001b[39m validate(model, valid_dataloader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Indonesian-Speech-to-text/main.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m display\u001b[39m.\u001b[39mclear_output(wait \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Indonesian-Speech-to-text/main.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m ground_truths \u001b[39m=\u001b[39m []\n",
      "\u001b[1;32md:\\Indonesian-Speech-to-text\\main.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Indonesian-Speech-to-text/main.ipynb#X26sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Indonesian-Speech-to-text/main.ipynb#X26sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Indonesian-Speech-to-text/main.ipynb#X26sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m validation_set:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Indonesian-Speech-to-text/main.ipynb#X26sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         source \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Indonesian-Speech-to-text/main.ipynb#X26sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         target \u001b[39m=\u001b[39m batch[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\KevinsAnaconda\\envs\\avalon-pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\KevinsAnaconda\\envs\\avalon-pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\KevinsAnaconda\\envs\\avalon-pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\KevinsAnaconda\\envs\\avalon-pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\Indonesian-Speech-to-text\\ops\\preprocess_per_audio.py:48\u001b[0m, in \u001b[0;36mAudioDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m     47\u001b[0m     audio_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maudio_dir, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranscriptions[\u001b[39m'\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m'\u001b[39m][idx])\n\u001b[1;32m---> 48\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_audio(audio_dir), torch\u001b[39m.\u001b[39mtensor(conv_char2num(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranscriptions[\u001b[39m'\u001b[39m\u001b[39msentence\u001b[39m\u001b[39m'\u001b[39m][idx]))\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32md:\\Indonesian-Speech-to-text\\ops\\preprocess_per_audio.py:59\u001b[0m, in \u001b[0;36mAudioDataset.load_audio\u001b[1;34m(self, audiofile)\u001b[0m\n\u001b[0;32m     56\u001b[0m     os\u001b[39m.\u001b[39mremove(audiofile)\n\u001b[0;32m     57\u001b[0m     audiofile \u001b[39m=\u001b[39m filename\n\u001b[1;32m---> 59\u001b[0m log_mel_spectrogram \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert2spectogram\u001b[39m.\u001b[39;49mtransform(audiofile)\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     60\u001b[0m \u001b[39m# except:\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39m#     print(f\"Error dalam mengambil audio, kemungkinan audio ini tidak memiliki aktivitas suara\")\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mtensor(add_padding(log_mel_spectrogram, n_mels \u001b[39m=\u001b[39m N_MELS, max_padding \u001b[39m=\u001b[39m \u001b[39m728\u001b[39m))\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32md:\\Indonesian-Speech-to-text\\ops\\preprocess_per_audio.py:29\u001b[0m, in \u001b[0;36mConvertWavToSpectogram.transform\u001b[1;34m(self, audio)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, audio): \u001b[39m# Make sure that the audio in mp3 format\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     waves, _ \u001b[39m=\u001b[39m conv2wav_torch(audio, \u001b[39m16000\u001b[39;49m)\n\u001b[0;32m     30\u001b[0m     signal_vad \u001b[39m=\u001b[39m vad_torch(waves, \u001b[39m1000\u001b[39m, \u001b[39m0.012\u001b[39m) \u001b[39m# Remove any moment of silence using VAD\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     mel_spectrogram \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmel_spectrogram_transform(torch\u001b[39m.\u001b[39mtensor(signal_vad)\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mfloat)) \u001b[39m# Transform the cleaned signal to Mel Spectogram\u001b[39;00m\n",
      "File \u001b[1;32md:\\Indonesian-Speech-to-text\\ops\\base_functions.py:42\u001b[0m, in \u001b[0;36mconv2wav_torch\u001b[1;34m(file_audio, resample)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconv2wav_torch\u001b[39m(file_audio, resample):\n\u001b[1;32m---> 42\u001b[0m     waves, sr \u001b[39m=\u001b[39m torchaudio\u001b[39m.\u001b[39;49mload(file_audio)\n\u001b[0;32m     43\u001b[0m     waves \u001b[39m=\u001b[39m F_ta\u001b[39m.\u001b[39mresample(waves, orig_freq\u001b[39m=\u001b[39msr, new_freq\u001b[39m=\u001b[39mresample)\n\u001b[0;32m     44\u001b[0m     \u001b[39mreturn\u001b[39;00m waves, resample\n",
      "File \u001b[1;32mc:\\KevinsAnaconda\\envs\\avalon-pytorch\\lib\\site-packages\\torchaudio\\_backend\\utils.py:203\u001b[0m, in \u001b[0;36mget_load_func.<locals>.load\u001b[1;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \n\u001b[0;32m    128\u001b[0m \u001b[39mBy default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[39m        `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    202\u001b[0m backend \u001b[39m=\u001b[39m dispatcher(uri, \u001b[39mformat\u001b[39m, backend)\n\u001b[1;32m--> 203\u001b[0m \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49mload(uri, frame_offset, num_frames, normalize, channels_first, \u001b[39mformat\u001b[39;49m, buffer_size)\n",
      "File \u001b[1;32mc:\\KevinsAnaconda\\envs\\avalon-pytorch\\lib\\site-packages\\torchaudio\\_backend\\soundfile.py:26\u001b[0m, in \u001b[0;36mSoundfileBackend.load\u001b[1;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[0;32m     18\u001b[0m     uri: Union[BinaryIO, \u001b[39mstr\u001b[39m, os\u001b[39m.\u001b[39mPathLike],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     buffer_size: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m4096\u001b[39m,\n\u001b[0;32m     25\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor, \u001b[39mint\u001b[39m]:\n\u001b[1;32m---> 26\u001b[0m     \u001b[39mreturn\u001b[39;00m soundfile_backend\u001b[39m.\u001b[39;49mload(uri, frame_offset, num_frames, normalize, channels_first, \u001b[39mformat\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\KevinsAnaconda\\envs\\avalon-pytorch\\lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:230\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001b[0m\n\u001b[0;32m    227\u001b[0m         dtype \u001b[39m=\u001b[39m _SUBTYPE2DTYPE[file_\u001b[39m.\u001b[39msubtype]\n\u001b[0;32m    229\u001b[0m     frames \u001b[39m=\u001b[39m file_\u001b[39m.\u001b[39m_prepare_read(frame_offset, \u001b[39mNone\u001b[39;00m, num_frames)\n\u001b[1;32m--> 230\u001b[0m     waveform \u001b[39m=\u001b[39m file_\u001b[39m.\u001b[39;49mread(frames, dtype, always_2d\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    231\u001b[0m     sample_rate \u001b[39m=\u001b[39m file_\u001b[39m.\u001b[39msamplerate\n\u001b[0;32m    233\u001b[0m waveform \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(waveform)\n",
      "File \u001b[1;32mc:\\KevinsAnaconda\\envs\\avalon-pytorch\\lib\\site-packages\\soundfile.py:895\u001b[0m, in \u001b[0;36mSoundFile.read\u001b[1;34m(self, frames, dtype, always_2d, fill_value, out)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[39mif\u001b[39;00m frames \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m frames \u001b[39m>\u001b[39m \u001b[39mlen\u001b[39m(out):\n\u001b[0;32m    894\u001b[0m         frames \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(out)\n\u001b[1;32m--> 895\u001b[0m frames \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_array_io(\u001b[39m'\u001b[39;49m\u001b[39mread\u001b[39;49m\u001b[39m'\u001b[39;49m, out, frames)\n\u001b[0;32m    896\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m>\u001b[39m frames:\n\u001b[0;32m    897\u001b[0m     \u001b[39mif\u001b[39;00m fill_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\KevinsAnaconda\\envs\\avalon-pytorch\\lib\\site-packages\\soundfile.py:1344\u001b[0m, in \u001b[0;36mSoundFile._array_io\u001b[1;34m(self, action, array, frames)\u001b[0m\n\u001b[0;32m   1342\u001b[0m \u001b[39massert\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mitemsize \u001b[39m==\u001b[39m _ffi\u001b[39m.\u001b[39msizeof(ctype)\n\u001b[0;32m   1343\u001b[0m cdata \u001b[39m=\u001b[39m _ffi\u001b[39m.\u001b[39mcast(ctype \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m, array\u001b[39m.\u001b[39m__array_interface__[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m])\n\u001b[1;32m-> 1344\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cdata_io(action, cdata, ctype, frames)\n",
      "File \u001b[1;32mc:\\KevinsAnaconda\\envs\\avalon-pytorch\\lib\\site-packages\\soundfile.py:1353\u001b[0m, in \u001b[0;36mSoundFile._cdata_io\u001b[1;34m(self, action, data, ctype, frames)\u001b[0m\n\u001b[0;32m   1351\u001b[0m     curr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtell()\n\u001b[0;32m   1352\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(_snd, \u001b[39m'\u001b[39m\u001b[39msf_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m action \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mf_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m ctype)\n\u001b[1;32m-> 1353\u001b[0m frames \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_file, data, frames)\n\u001b[0;32m   1354\u001b[0m _error_check(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_errorcode)\n\u001b[0;32m   1355\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseekable():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10000\n",
    "lowest_wer = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss, total_wer, avg_wer = 0, 0, 0\n",
    "\n",
    "    for batch_src, batch_tgt in tqdm(train_dataloader, desc = f\"Training on Epoch {epoch + 1} \", leave = False):\n",
    "        loss = train_step(model, optimizer, [batch_src, batch_tgt])\n",
    "        epoch_loss += loss['Loss']\n",
    "    \n",
    "    avg_epoch_loss = epoch_loss / len(train_dataloader)\n",
    "    validation_loss = validate(model, valid_dataloader)\n",
    "    display.clear_output(wait = True)\n",
    "\n",
    "    ground_truths = []\n",
    "\n",
    "    for batch_src, batch_tgt in tqdm(valid_dataloader, desc = f\"Inferencing Validation Set\", leave = False):\n",
    "        for batch_tgt_item in batch_tgt:\n",
    "            ground_truths.append(conv_num2char(batch_tgt_item.cpu().numpy()))\n",
    "        \n",
    "        prediction = model.generate(batch_src.float(), start_token_id)\n",
    "\n",
    "        for id, item in enumerate(prediction):\n",
    "            prediction_text = conv_num2char(item.detach().cpu().numpy())\n",
    "            matches = re.findall(r'<[a-zA-Z\\s]+>', prediction_text)\n",
    "            cleaned_text = matches[0] if matches else None\n",
    "            try:\n",
    "                print(f\"Ground truth {id} => \", ground_truths[id])\n",
    "                print(f\"Generation {id}   => \", cleaned_text)\n",
    "                total_wer += wer(ground_truths[id], cleaned_text)\n",
    "                avg_wer = total_wer / len(ground_truths)\n",
    "            except:\n",
    "                print(\"Ada kesalahan saat menghitung WER\")\n",
    "            \n",
    "            print('-------------------------------------------------------------------------')\n",
    "        \n",
    "        break\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(\"===============================================================================\")\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Mean Loss: {avg_epoch_loss:.4f}\")\n",
    "        print(f\"Validation Loss : {validation_loss:.4f}\")\n",
    "        print(f\"WER Score       : {avg_wer}\")\n",
    "        print(f\"Lowest WER      : {lowest_wer}\")\n",
    "        print(\"===============================================================================\")\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    if avg_wer < lowest_wer:\n",
    "        lowest_wer = avg_wer\n",
    "        torch.save(model, './config/best_wer_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avalon-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
