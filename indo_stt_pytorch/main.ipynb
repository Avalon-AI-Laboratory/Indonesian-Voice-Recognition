{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><u>Ringkasan</u></h2>\n",
    "\n",
    "Dalam proyek ini, kami mencoba menerapkan arsitektur Transformer yang terinspirasi dari paper Attention is All You Need (oleh Google Brain) dan arsitektur Whisper dari OpenAI untuk melakukan Automatic Speech Recognition dalam bahasa Indonesia. Data yang digunakan dalam proyek ini adalah Common Voice (sumber: huggingface) untuk bahasa Indonesia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import Necessary Libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import torchaudio.functional as F_audio\n",
    "import torchaudio.transforms as T\n",
    "from torchinfo import summary\n",
    "import seaborn as sns\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import string\n",
    "\n",
    "from PreprocessAudio import PreprocessAudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Read and Clean the Metadatas</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadata ini akan digunakan untuk membuat dataset. Pertama, diperlukan metadata dengan format ```audio_file_path, transcription```. Pada proyek ini, transkripsi audio diharapkan dapat menebak kata-kata yang dieja dalam file audio dengan benar, sehingga keberadaan tanda baca atau huruf kapital dapat diabaikan. Hal ini juga bersifat menguntungkan karena dapat meningkatkan akurasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv('./common_voice_id/dev.tsv', sep='\\t')\n",
    "df2 = pd.read_csv('./common_voice_id/invalidated.tsv', sep='\\t')\n",
    "df3 = pd.read_csv('./common_voice_id/other.tsv', sep='\\t')\n",
    "df4 = pd.read_csv('./common_voice_id/train.tsv', sep='\\t')\n",
    "\n",
    "df  = df[['path', 'sentence']]\n",
    "df2 = df2[['path', 'sentence']]\n",
    "df3 = df3[['path', 'sentence']]\n",
    "df4 = df4[['path', 'sentence']]\n",
    "\n",
    "df = pd.concat([df, df2, df3, df4], ignore_index=True)\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>common_voice_id_26747327.mp3</td>\n",
       "      <td>Kamu harus melakukannya, suka tidak suka.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>common_voice_id_21699230.mp3</td>\n",
       "      <td>Saya dibonceng di belakang sepeda teman.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>common_voice_id_25248896.mp3</td>\n",
       "      <td>Tom berkata dia dapat menunggu lama.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>common_voice_id_25537482.mp3</td>\n",
       "      <td>Minggu lalu terus-menerus hujan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>common_voice_id_21195036.mp3</td>\n",
       "      <td>Saat libur musim panas tahun ini saya pergi ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40199</th>\n",
       "      <td>common_voice_id_25039385.mp3</td>\n",
       "      <td>Aku menyuruh adikku untuk membeli gula di warung.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40200</th>\n",
       "      <td>common_voice_id_25426706.mp3</td>\n",
       "      <td>perusahaan yang berkembang selalu diikuti deng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40201</th>\n",
       "      <td>common_voice_id_26229445.mp3</td>\n",
       "      <td>Melepaskan yang melekat membawa ke Nirvana.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40202</th>\n",
       "      <td>common_voice_id_20954419.mp3</td>\n",
       "      <td>dia tidak pernah ke dokter gigi selama hidupnya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40203</th>\n",
       "      <td>common_voice_id_25775886.mp3</td>\n",
       "      <td>Saya kemarin membeli sepatu putih di toserba.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40204 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               path  \\\n",
       "0      common_voice_id_26747327.mp3   \n",
       "1      common_voice_id_21699230.mp3   \n",
       "2      common_voice_id_25248896.mp3   \n",
       "3      common_voice_id_25537482.mp3   \n",
       "4      common_voice_id_21195036.mp3   \n",
       "...                             ...   \n",
       "40199  common_voice_id_25039385.mp3   \n",
       "40200  common_voice_id_25426706.mp3   \n",
       "40201  common_voice_id_26229445.mp3   \n",
       "40202  common_voice_id_20954419.mp3   \n",
       "40203  common_voice_id_25775886.mp3   \n",
       "\n",
       "                                                sentence  \n",
       "0              Kamu harus melakukannya, suka tidak suka.  \n",
       "1               Saya dibonceng di belakang sepeda teman.  \n",
       "2                   Tom berkata dia dapat menunggu lama.  \n",
       "3                       Minggu lalu terus-menerus hujan.  \n",
       "4      Saat libur musim panas tahun ini saya pergi ke...  \n",
       "...                                                  ...  \n",
       "40199  Aku menyuruh adikku untuk membeli gula di warung.  \n",
       "40200  perusahaan yang berkembang selalu diikuti deng...  \n",
       "40201        Melepaskan yang melekat membawa ke Nirvana.  \n",
       "40202    dia tidak pernah ke dokter gigi selama hidupnya  \n",
       "40203      Saya kemarin membeli sepatu putih di toserba.  \n",
       "\n",
       "[40204 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testing = df[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevin Putra Santoso\\AppData\\Local\\Temp\\ipykernel_33144\\2679286301.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing['sentence'][i] = df_testing['sentence'][i].lower()\n",
      "C:\\Users\\Kevin Putra Santoso\\AppData\\Local\\Temp\\ipykernel_33144\\2679286301.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing['sentence'][i] = ' '.join(word.strip(string.punctuation) for word in df_testing['sentence'][i].split())\n",
      "C:\\Users\\Kevin Putra Santoso\\AppData\\Local\\Temp\\ipykernel_33144\\2679286301.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing['sentence'][i] = ' '.join(remove_strips(word) for word in df_testing['sentence'][i].split())\n"
     ]
    }
   ],
   "source": [
    "def remove_strips(text):\n",
    "    # Mengganti tanda hubung (-) dengan spasi dan menghapus tanda baca di awal dan akhir kata\n",
    "    cleaned_text = text.replace('“', '')\n",
    "    cleaned_text = cleaned_text.replace('”', '')\n",
    "    cleaned_text = cleaned_text.replace('-', ' ')\n",
    "    cleaned_text = cleaned_text.strip(string.punctuation)\n",
    "    return cleaned_text\n",
    "\n",
    "for i in range(len(df_testing['sentence'])):\n",
    "    # print(text)\n",
    "    df_testing['sentence'][i] = df_testing['sentence'][i].lower()\n",
    "    df_testing['sentence'][i] = ' '.join(word.strip(string.punctuation) for word in df_testing['sentence'][i].split())\n",
    "    df_testing['sentence'][i] = ' '.join(remove_strips(word) for word in df_testing['sentence'][i].split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dipersiapkan sebuah direktori untuk menyimpan audio yang akan diolah dan nantinya akan dikelompokkan dalam data train dan validasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = []\n",
    "HOME = os.getcwd()\n",
    "for i in range(len(df_testing)):\n",
    "    os.system(f'copy \\\"{HOME}\\\\common_voice_id\\\\clips\\\\{df_testing[\"path\"][i]}\\\" \\\"{HOME}\\\\audio_folder\\\\{df_testing[\"path\"][i]}\\\"')\n",
    "    label_list.append(df_testing['sentence'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banyaknya label: 500\n",
      "Sampel 10 label\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['kamu harus melakukannya suka tidak suka',\n",
       " 'saya dibonceng di belakang sepeda teman',\n",
       " 'tom berkata dia dapat menunggu lama',\n",
       " 'minggu lalu terus menerus hujan',\n",
       " 'saat libur musim panas tahun ini saya pergi ke laut dan mendaki gunung',\n",
       " 'dia memanggil namanya',\n",
       " 'saat berada di sana saya belajar bahasa inggris',\n",
       " 'di mana kamu membeli buku itu',\n",
       " 'sepuluh tahun adalah waktu yang lama untuk menunggu',\n",
       " 'di atas meja ada vas bunga']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Banyaknya label: {len(label_list)}')\n",
    "print('Sampel 10 label')\n",
    "label_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset yang akan kita latih diharapkan memiliki format sebagai berikut.\n",
    "\n",
    "```python\n",
    "[[tensor_1], [transcription_1],\n",
    " [tensor_2], [transcription_2],\n",
    " ...\n",
    " [tensor_n], [transcription_n]]\n",
    "```\n",
    "\n",
    "Untuk itu modul ```Dataset``` oleh PyTorch dapat digunakan untuk membuat dataset ini. Modul ini dipanggil dengan syntax\n",
    "\n",
    "```python\n",
    "from torch.utils.data import Dataset\n",
    "```\n",
    "\n",
    "dengan ukuran batch (batch size) sebesar 64.\n",
    "\n",
    "tensor_i adalah tensor yang memuat matriks MFCC dari sebuah audio. Meninjau ulang bahwa sebuah matriks MFCC memiliki ukuran ```(n_mfcc, timesteps)``` dengan ```n_mfcc=64``` dan timesteps bergantung dari audio yang memiliki durasi terpanjang (timesteps tidak sama dengan durasi audio).\n",
    "\n",
    "transcription_i adalah tensor yang memuat transkripsi yang telah di encode menjadi angka dalam dictionary encoder yang ditentukan oleh user (biasa disebut sebagai vocabulary). tensor ini memiliki ukuran ```(1, max_len)``` dimana ```max_len``` adalah transkripsi terpanjang dari sebuah audio. Perlu diingat bahwa panjang transkripsi maksimum akan dibatasi sebesar 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = 'abcdefghijklmnopqrstuvwxyz '\n",
    "max_timestamps = 2752\n",
    "max_len = 256\n",
    "\n",
    "alphabets = ['', ' '] + [chr(i + 96) for i in range(1, 27)]\n",
    "char2num_dict, num2char_dict = {}, {}\n",
    "\n",
    "for index, chars in enumerate(alphabets):\n",
    "    char2num_dict[chars] = index\n",
    "    num2char_dict[index] = chars\n",
    "\n",
    "def conv_char2num(label, maxlen=max_len):\n",
    "    label = label[:maxlen].lower()\n",
    "    label_enc = []\n",
    "    padding_len = maxlen - len(label)\n",
    "    for i in label:\n",
    "        label_enc.append(char2num_dict[i])\n",
    "    return np.array(label_enc + [0] * padding_len)\n",
    "\n",
    "def conv_num2char(num):\n",
    "    txt = \"\"\n",
    "    for i in num:\n",
    "        if i == 0:\n",
    "            break\n",
    "        else:\n",
    "            txt += num2char_dict[i]\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20  2 26  2  1  3  6 19  2 15  8 12  2 21  1 12  6  1 20  6 12 16 13  2\n",
      "  9  1  5 10  1 17  2  8 10  1  9  2 19 10  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "example_text = 'Saya berangkat ke sekolah di pagi hari'\n",
    "print(conv_char2num(example_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, test_size=0.8):\n",
    "    data_size = len(df)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    split = int(test_size * data_size)\n",
    "    df_train, df_valid = df[:split], df[split:]\n",
    "    df_train\n",
    "    \n",
    "    return df_train, df_valid.reset_index(drop=True)\n",
    "\n",
    "df_train, df_valid = split_data(df_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy train audio data to 'train' folder\n",
    "label_list_train = []\n",
    "\n",
    "for i in range(len(df_train)):\n",
    "    os.system(f'move \\\"{HOME}\\\\audio_folder\\\\{df_train[\"path\"][i]}\\\" \\\"{HOME}\\\\audio_folder\\\\train\\\\{df_train[\"path\"][i]}\\\"')\n",
    "    label_list_train.append(df_train['sentence'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy train audio data to 'valid' folder\n",
    "label_list_valid = []\n",
    "\n",
    "for i in range(len(df_valid)):\n",
    "    os.system(f'move \\\"{HOME}\\\\audio_folder\\\\{df_valid[\"path\"][i]}\\\" \\\"{HOME}\\\\audio_folder\\\\valid\\\\{df_valid[\"path\"][i]}\\\"')\n",
    "    label_list_valid.append(df_valid['sentence'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PipelineTrain = PreprocessAudio('./audio_folder/train/', df_train, 35)\n",
    "PipelineValid = PreprocessAudio('./audio_folder/valid/', df_valid, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted audio directory at: ./audio_folder/train/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kevin Putra Santoso\\Documents\\IVR_Project\\PreprocessAudio.py:34: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  return torch.tensor([signal])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter di 2\n",
      "Error di file ./audio_folder/train/common_voice_id_21192699.mp3\n",
      "Counter di 108\n",
      "Error di file ./audio_folder/train/common_voice_id_21194463.mp3\n",
      "Counter di 162\n",
      "Error di file ./audio_folder/train/common_voice_id_26242833.mp3\n",
      "Counter di 174\n",
      "Error di file ./audio_folder/train/common_voice_id_21699467.mp3\n",
      "Counter di 179\n",
      "Error di file ./audio_folder/train/common_voice_id_20847480.mp3\n",
      "Counter di 188\n",
      "Error di file ./audio_folder/train/common_voice_id_21194346.mp3\n",
      "Counter di 317\n",
      "Error di file ./audio_folder/train/common_voice_id_35338065.mp3\n",
      "Counter di 329\n",
      "Error di file ./audio_folder/train/common_voice_id_26237570.mp3\n",
      "Counter di 343\n",
      "Error di file ./audio_folder/train/common_voice_id_19783809.mp3\n",
      "Counter di 350\n",
      "Error di file ./audio_folder/train/common_voice_id_21587706.mp3\n",
      "Counter di 389\n",
      "Error di file ./audio_folder/train/common_voice_id_25469455.mp3\n",
      "Mounted audio directory at: ./audio_folder/valid/\n",
      "Counter di 31\n",
      "Error di file ./audio_folder/valid/common_voice_id_25470004.mp3\n"
     ]
    }
   ],
   "source": [
    "dataset_train, df_train_filtered = PipelineTrain.load_audio()\n",
    "dataset_valid, df_valid_filtered = PipelineValid.load_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding(mfcc_tensor, index, n_mfcc=64, max_padding=512):\n",
    "    height, width = np.array(mfcc_tensor[index][0]).shape[0], np.array(mfcc_tensor[index][0]).shape[1]\n",
    "    \n",
    "    padded_mfcc = np.zeros([max_padding, n_mfcc])\n",
    "    padded_mfcc[:height, :width] = mfcc_tensor[index][0]\n",
    "    return padded_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_list = []\n",
    "for i in range(len(dataset_train)):\n",
    "    train_dataset_list.append(add_padding(dataset_train, i, max_padding=max_timestamps).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset_list = []\n",
    "for i in range(len(dataset_valid)):\n",
    "    valid_dataset_list.append(add_padding(dataset_valid, i, max_padding=max_timestamps).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_list = torch.tensor(train_dataset_list)\n",
    "valid_dataset_list = torch.tensor(valid_dataset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_x = train_dataset_list.to(device)\n",
    "valid_x = valid_dataset_list.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>common_voice_id_26009087.mp3</td>\n",
       "      <td>tetapi apa yang bisa dia lakukan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>common_voice_id_25448391.mp3</td>\n",
       "      <td>ini kok lemot ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>common_voice_id_35281926.mp3</td>\n",
       "      <td>dari stasiun sampai perusahaan saya naik taksi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>common_voice_id_35507973.mp3</td>\n",
       "      <td>saya mengambil banyak foto saat jalan jalan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>common_voice_id_26628186.mp3</td>\n",
       "      <td>saya tahu dia tidak dapat bekerja lagi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           path  \\\n",
       "0  common_voice_id_26009087.mp3   \n",
       "1  common_voice_id_25448391.mp3   \n",
       "2  common_voice_id_35281926.mp3   \n",
       "3  common_voice_id_35507973.mp3   \n",
       "4  common_voice_id_26628186.mp3   \n",
       "\n",
       "                                         sentence  \n",
       "0                tetapi apa yang bisa dia lakukan  \n",
       "1                                ini kok lemot ya  \n",
       "2  dari stasiun sampai perusahaan saya naik taksi  \n",
       "3     saya mengambil banyak foto saat jalan jalan  \n",
       "4          saya tahu dia tidak dapat bekerja lagi  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y, valid_y = [], []\n",
    "\n",
    "for text in df_train_filtered['sentence']:\n",
    "    train_y.append(conv_char2num(text))\n",
    "\n",
    "for text in df_valid_filtered['sentence']:\n",
    "    valid_y.append(conv_char2num(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = torch.tensor(train_y)\n",
    "valid_y = torch.tensor(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class myDataset(Dataset):\n",
    "    def __init__(self, data, transcriptions):\n",
    "        self.data = data\n",
    "        self.transcriptions = transcriptions\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        mfcc_matrix = self.data[index]\n",
    "        transcription = self.transcriptions[index]\n",
    "        return mfcc_matrix, transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_train_dataset = myDataset(train_x, train_y)\n",
    "my_valid_dataset = myDataset(valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_set = DataLoader(my_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_set = DataLoader(my_valid_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Build Transformer Model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        error_const = torch.erf(x / math.sqrt(2.0))\n",
    "        x = x * 0.5 * (1.0 + error_const)\n",
    "        return x\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, num_vocab=30, num_hid=64):\n",
    "        super().__init__()\n",
    "        self.num_vocab = num_vocab\n",
    "        self.num_hid = num_hid\n",
    "\n",
    "    def forward(self, x):\n",
    "        maxlen = x.shape[-1]\n",
    "        pos = torch.arange(0, maxlen, 1)\n",
    "        emb = nn.Embedding(num_vocab, num_hid)(x)\n",
    "        pos_emb = nn.Embedding(maxlen, num_hid)(x)\n",
    "        return emb + pos_emb\n",
    "\n",
    "class SpeechFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, num_hid=64, maxlen=100):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=num_hid, out_channels=num_hid, kernel_size=11, stride=2, padding=5)\n",
    "        self.conv2 = nn.Conv1d(in_channels=num_hid, out_channels=num_hid, kernel_size=11, stride=2, padding=5)\n",
    "        self.conv3 = nn.Conv1d(in_channels=num_hid, out_channels=num_hid, kernel_size=11, stride=2, padding=5)\n",
    "        self.gelu = GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x.T)\n",
    "        x = self.gelu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.gelu(x)\n",
    "        return x\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.att = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, feed_forward_dim),\n",
    "            GELU(),\n",
    "            nn.Linear(feed_forward_dim, embed_dim)\n",
    "        )\n",
    "        self.layernorm1 = nn.LayerNorm(embed_dim, eps=1e-6)\n",
    "        self.layernorm2 = nn.LayerNorm(embed_dim, eps=1e-6)\n",
    "        self.dropout1 = nn.Dropout(rate)\n",
    "        self.dropout2 = nn.Dropout(rate)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = inputs.T\n",
    "        attn_output = self.att(inputs, inputs, inputs)[0]\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.layernorm1 = nn.LayerNorm(embed_dim, eps=1e-6)\n",
    "        self.layernorm2 = nn.LayerNorm(embed_dim, eps=1e-6)\n",
    "        self.layernorm3 = nn.LayerNorm(embed_dim, eps=1e-6)\n",
    "        self.self_att = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "        self.enc_att = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "        self.self_dropout = nn.Dropout(0.5)\n",
    "        self.enc_dropout = nn.Dropout(0.1)\n",
    "        self.ffn_dropout = nn.Dropout(0.1)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, feed_forward_dim),\n",
    "            GELU(),\n",
    "            nn.Linear(feed_forward_dim, embed_dim)\n",
    "        )\n",
    "\n",
    "    def causalAttentionMask(self, batch_size, n_dest, n_src, dtype):\n",
    "        i = torch.arange(n_dest)[:, None]\n",
    "        j = torch.arange(n_src)\n",
    "        m = i >= j - n_src + n_dest\n",
    "        mask = m.to(dtype)\n",
    "        mask = mask.reshape(1, n_dest, n_src)\n",
    "        mult = torch.cat([torch.tensor([batch_size], dtype=torch.int32), torch.tensor([1, 1], dtype=torch.int32)])\n",
    "        mult = mult.unsqueeze(0)\n",
    "        return mask.expand(*mult)\n",
    "\n",
    "    def forward(self, enc_out, target):\n",
    "        input_shape = target.shape\n",
    "        batch_size = input_shape[0]\n",
    "        seq_len = input_shape[1]\n",
    "        causal_mask = self.causalAttentionMask(batch_size, seq_len, seq_len, target.dtype)\n",
    "        target_att = self.self_att(target, target, target, att_mask=causal_mask)[0]\n",
    "        target_norm = self.layernorm1(target + self.self_dropout(target_att))\n",
    "        enc_out = self.enc_att(target_norm, target_norm, enc_out)[0]\n",
    "        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out) + target_norm)\n",
    "        ffn_out = self.ffn(enc_out_norm)\n",
    "        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out))\n",
    "        return ffn_out_norm\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_hid = 64,\n",
    "        num_head = 2,\n",
    "        num_feed_forward = 128,\n",
    "        source_maxlen = 100,\n",
    "        target_maxlen = 100,\n",
    "        num_layers_enc = 4,\n",
    "        num_layers_dec = 1,\n",
    "        num_classes = 10\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.loss_metric = nn.MSELoss()\n",
    "        self.num_layers_enc = num_layers_enc\n",
    "        self.num_layers_dec = num_layers_dec\n",
    "        self.target_maxlen = target_maxlen\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.enc_input = SpeechFeatureEmbedding(num_hid=num_hid, maxlen=source_maxlen)\n",
    "        self.dec_input = TokenEmbedding(num_vocab=num_classes, num_hid=num_hid)\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            self.enc_input,\n",
    "            *[TransformerEncoder(num_hid, num_head, num_feed_forward) for _ in range(num_layers_enc)]\n",
    "        )\n",
    "\n",
    "        for i in range(num_layers_dec):\n",
    "            self.add_module(\n",
    "                f\"dec_layer_{i}\",\n",
    "                TransformerDecoder(num_hid, num_head, num_feed_forward),\n",
    "            )\n",
    "\n",
    "        self.classifier = nn.Linear(num_hid, num_classes)\n",
    "\n",
    "    def decode(self, enc_out, target):\n",
    "        y = self.dec_input(target)\n",
    "        for i in range(self.num_layers_dec):\n",
    "            dec_layer = getattr(self, f\"dec_layer_{i}\")\n",
    "            y = dec_layer(enc_out, y)\n",
    "        return y\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        source = inputs[0]\n",
    "        target = inputs[1]\n",
    "        x = self.encoder(source)\n",
    "        y = self.decode(x, target)\n",
    "        return self.classifier(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avalon_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
