{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><u>Ringkasan</u></h2>\n",
    "\n",
    "Dalam proyek ini, kami mencoba menerapkan arsitektur Transformer yang terinspirasi dari paper Attention is All You Need (oleh Google Brain) dan arsitektur Whisper dari OpenAI untuk melakukan Automatic Speech Recognition dalam bahasa Indonesia. Data yang digunakan dalam proyek ini adalah Common Voice (sumber: huggingface) untuk bahasa Indonesia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import Necessary Libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import torchaudio.functional as F_audio\n",
    "import torchaudio.transforms as T\n",
    "from torchinfo import summary\n",
    "import seaborn as sns\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import string\n",
    "\n",
    "from PreprocessAudio import PreprocessAudio\n",
    "from model import Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Read and Clean the Metadatas</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadata ini akan digunakan untuk membuat dataset. Pertama, diperlukan metadata dengan format ```audio_file_path, transcription```. Pada proyek ini, transkripsi audio diharapkan dapat menebak kata-kata yang dieja dalam file audio dengan benar, sehingga keberadaan tanda baca atau huruf kapital dapat diabaikan. Hal ini juga bersifat menguntungkan karena dapat meningkatkan akurasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv('./common_voice_id/dev.tsv', sep='\\t')\n",
    "df2 = pd.read_csv('./common_voice_id/invalidated.tsv', sep='\\t')\n",
    "df3 = pd.read_csv('./common_voice_id/other.tsv', sep='\\t')\n",
    "df4 = pd.read_csv('./common_voice_id/train.tsv', sep='\\t')\n",
    "\n",
    "df  = df[['path', 'sentence']]\n",
    "df2 = df2[['path', 'sentence']]\n",
    "df3 = df3[['path', 'sentence']]\n",
    "df4 = df4[['path', 'sentence']]\n",
    "\n",
    "df = pd.concat([df, df2, df3, df4], ignore_index=True)\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>common_voice_id_26747327.mp3</td>\n",
       "      <td>Kamu harus melakukannya, suka tidak suka.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>common_voice_id_21699230.mp3</td>\n",
       "      <td>Saya dibonceng di belakang sepeda teman.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>common_voice_id_25248896.mp3</td>\n",
       "      <td>Tom berkata dia dapat menunggu lama.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>common_voice_id_25537482.mp3</td>\n",
       "      <td>Minggu lalu terus-menerus hujan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>common_voice_id_21195036.mp3</td>\n",
       "      <td>Saat libur musim panas tahun ini saya pergi ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40199</th>\n",
       "      <td>common_voice_id_25039385.mp3</td>\n",
       "      <td>Aku menyuruh adikku untuk membeli gula di warung.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40200</th>\n",
       "      <td>common_voice_id_25426706.mp3</td>\n",
       "      <td>perusahaan yang berkembang selalu diikuti deng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40201</th>\n",
       "      <td>common_voice_id_26229445.mp3</td>\n",
       "      <td>Melepaskan yang melekat membawa ke Nirvana.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40202</th>\n",
       "      <td>common_voice_id_20954419.mp3</td>\n",
       "      <td>dia tidak pernah ke dokter gigi selama hidupnya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40203</th>\n",
       "      <td>common_voice_id_25775886.mp3</td>\n",
       "      <td>Saya kemarin membeli sepatu putih di toserba.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40204 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               path  \\\n",
       "0      common_voice_id_26747327.mp3   \n",
       "1      common_voice_id_21699230.mp3   \n",
       "2      common_voice_id_25248896.mp3   \n",
       "3      common_voice_id_25537482.mp3   \n",
       "4      common_voice_id_21195036.mp3   \n",
       "...                             ...   \n",
       "40199  common_voice_id_25039385.mp3   \n",
       "40200  common_voice_id_25426706.mp3   \n",
       "40201  common_voice_id_26229445.mp3   \n",
       "40202  common_voice_id_20954419.mp3   \n",
       "40203  common_voice_id_25775886.mp3   \n",
       "\n",
       "                                                sentence  \n",
       "0              Kamu harus melakukannya, suka tidak suka.  \n",
       "1               Saya dibonceng di belakang sepeda teman.  \n",
       "2                   Tom berkata dia dapat menunggu lama.  \n",
       "3                       Minggu lalu terus-menerus hujan.  \n",
       "4      Saat libur musim panas tahun ini saya pergi ke...  \n",
       "...                                                  ...  \n",
       "40199  Aku menyuruh adikku untuk membeli gula di warung.  \n",
       "40200  perusahaan yang berkembang selalu diikuti deng...  \n",
       "40201        Melepaskan yang melekat membawa ke Nirvana.  \n",
       "40202    dia tidak pernah ke dokter gigi selama hidupnya  \n",
       "40203      Saya kemarin membeli sepatu putih di toserba.  \n",
       "\n",
       "[40204 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testing = df[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevin Putra Santoso\\AppData\\Local\\Temp\\ipykernel_11004\\2679286301.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing['sentence'][i] = df_testing['sentence'][i].lower()\n",
      "C:\\Users\\Kevin Putra Santoso\\AppData\\Local\\Temp\\ipykernel_11004\\2679286301.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing['sentence'][i] = ' '.join(word.strip(string.punctuation) for word in df_testing['sentence'][i].split())\n",
      "C:\\Users\\Kevin Putra Santoso\\AppData\\Local\\Temp\\ipykernel_11004\\2679286301.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_testing['sentence'][i] = ' '.join(remove_strips(word) for word in df_testing['sentence'][i].split())\n"
     ]
    }
   ],
   "source": [
    "def remove_strips(text):\n",
    "    # Mengganti tanda hubung (-) dengan spasi dan menghapus tanda baca di awal dan akhir kata\n",
    "    cleaned_text = text.replace('“', '')\n",
    "    cleaned_text = cleaned_text.replace('”', '')\n",
    "    cleaned_text = cleaned_text.replace('-', ' ')\n",
    "    cleaned_text = cleaned_text.strip(string.punctuation)\n",
    "    return cleaned_text\n",
    "\n",
    "for i in range(len(df_testing['sentence'])):\n",
    "    # print(text)\n",
    "    df_testing['sentence'][i] = df_testing['sentence'][i].lower()\n",
    "    df_testing['sentence'][i] = ' '.join(word.strip(string.punctuation) for word in df_testing['sentence'][i].split())\n",
    "    df_testing['sentence'][i] = ' '.join(remove_strips(word) for word in df_testing['sentence'][i].split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dipersiapkan sebuah direktori untuk menyimpan audio yang akan diolah dan nantinya akan dikelompokkan dalam data train dan validasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = []\n",
    "HOME = os.getcwd()\n",
    "for i in range(len(df_testing)):\n",
    "    os.system(f'copy \\\"{HOME}\\\\common_voice_id\\\\clips\\\\{df_testing[\"path\"][i]}\\\" \\\"{HOME}\\\\audio_folder\\\\{df_testing[\"path\"][i]}\\\"')\n",
    "    label_list.append(df_testing['sentence'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banyaknya label: 500\n",
      "Sampel 10 label\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['kamu harus melakukannya suka tidak suka',\n",
       " 'saya dibonceng di belakang sepeda teman',\n",
       " 'tom berkata dia dapat menunggu lama',\n",
       " 'minggu lalu terus menerus hujan',\n",
       " 'saat libur musim panas tahun ini saya pergi ke laut dan mendaki gunung',\n",
       " 'dia memanggil namanya',\n",
       " 'saat berada di sana saya belajar bahasa inggris',\n",
       " 'di mana kamu membeli buku itu',\n",
       " 'sepuluh tahun adalah waktu yang lama untuk menunggu',\n",
       " 'di atas meja ada vas bunga']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Banyaknya label: {len(label_list)}')\n",
    "print('Sampel 10 label')\n",
    "label_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset yang akan kita latih diharapkan memiliki format sebagai berikut.\n",
    "\n",
    "```python\n",
    "[[tensor_1], [transcription_1],\n",
    " [tensor_2], [transcription_2],\n",
    " ...\n",
    " [tensor_n], [transcription_n]]\n",
    "```\n",
    "\n",
    "Untuk itu modul ```Dataset``` oleh PyTorch dapat digunakan untuk membuat dataset ini. Modul ini dipanggil dengan syntax\n",
    "\n",
    "```python\n",
    "from torch.utils.data import Dataset\n",
    "```\n",
    "\n",
    "dengan ukuran batch (batch size) sebesar 64.\n",
    "\n",
    "tensor_i adalah tensor yang memuat matriks MFCC dari sebuah audio. Meninjau ulang bahwa sebuah matriks MFCC memiliki ukuran ```(n_mfcc, timesteps)``` dengan ```n_mfcc=64``` dan timesteps bergantung dari audio yang memiliki durasi terpanjang (timesteps tidak sama dengan durasi audio).\n",
    "\n",
    "transcription_i adalah tensor yang memuat transkripsi yang telah di encode menjadi angka dalam dictionary encoder yang ditentukan oleh user (biasa disebut sebagai vocabulary). tensor ini memiliki ukuran ```(1, max_len)``` dimana ```max_len``` adalah transkripsi terpanjang dari sebuah audio. Perlu diingat bahwa panjang transkripsi maksimum akan dibatasi sebesar 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = 'abcdefghijklmnopqrstuvwxyz '\n",
    "max_timestamps = 2752\n",
    "max_len = 256\n",
    "\n",
    "alphabets = ['', ' '] + [chr(i + 96) for i in range(1, 27)]\n",
    "char2num_dict, num2char_dict = {}, {}\n",
    "\n",
    "for index, chars in enumerate(alphabets):\n",
    "    char2num_dict[chars] = index\n",
    "    num2char_dict[index] = chars\n",
    "\n",
    "def conv_char2num(label, maxlen=max_len):\n",
    "    label = label[:maxlen].lower()\n",
    "    label_enc = []\n",
    "    padding_len = maxlen - len(label)\n",
    "    for i in label:\n",
    "        label_enc.append(char2num_dict[i])\n",
    "    return np.array(label_enc + [0] * padding_len)\n",
    "\n",
    "def conv_num2char(num):\n",
    "    txt = \"\"\n",
    "    for i in num:\n",
    "        if i == 0:\n",
    "            break\n",
    "        else:\n",
    "            txt += num2char_dict[i]\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20  2 26  2  1  3  6 19  2 15  8 12  2 21  1 12  6  1 20  6 12 16 13  2\n",
      "  9  1  5 10  1 17  2  8 10  1  9  2 19 10  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "example_text = 'Saya berangkat ke sekolah di pagi hari'\n",
    "print(conv_char2num(example_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, test_size=0.8):\n",
    "    data_size = len(df)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    split = int(test_size * data_size)\n",
    "    df_train, df_valid = df[:split], df[split:]\n",
    "    df_train\n",
    "    \n",
    "    return df_train, df_valid.reset_index(drop=True)\n",
    "\n",
    "df_train, df_valid = split_data(df_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy train audio data to 'train' folder\n",
    "label_list_train = []\n",
    "\n",
    "for i in range(len(df_train)):\n",
    "    os.system(f'move \\\"{HOME}\\\\audio_folder\\\\{df_train[\"path\"][i]}\\\" \\\"{HOME}\\\\audio_folder\\\\train\\\\{df_train[\"path\"][i]}\\\"')\n",
    "    label_list_train.append(df_train['sentence'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy train audio data to 'valid' folder\n",
    "label_list_valid = []\n",
    "\n",
    "for i in range(len(df_valid)):\n",
    "    os.system(f'move \\\"{HOME}\\\\audio_folder\\\\{df_valid[\"path\"][i]}\\\" \\\"{HOME}\\\\audio_folder\\\\valid\\\\{df_valid[\"path\"][i]}\\\"')\n",
    "    label_list_valid.append(df_valid['sentence'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PipelineTrain = PreprocessAudio('./audio_folder/train/', df_train, 35)\n",
    "PipelineValid = PreprocessAudio('./audio_folder/valid/', df_valid, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted audio directory at: ./audio_folder/train/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kevin Putra Santoso\\Documents\\IVR_Project\\PreprocessAudio.py:34: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  return torch.tensor([signal])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter di 12\n",
      "Error di file ./audio_folder/train/common_voice_id_21587706.mp3\n",
      "Counter di 38\n",
      "Error di file ./audio_folder/train/common_voice_id_19783809.mp3\n",
      "Counter di 95\n",
      "Error di file ./audio_folder/train/common_voice_id_21194463.mp3\n",
      "Counter di 109\n",
      "Error di file ./audio_folder/train/common_voice_id_25470004.mp3\n",
      "Counter di 163\n",
      "Error di file ./audio_folder/train/common_voice_id_25469455.mp3\n",
      "Counter di 217\n",
      "Error di file ./audio_folder/train/common_voice_id_21194346.mp3\n",
      "Counter di 219\n",
      "Error di file ./audio_folder/train/common_voice_id_26242833.mp3\n",
      "Counter di 346\n",
      "Error di file ./audio_folder/train/common_voice_id_21699467.mp3\n",
      "Mounted audio directory at: ./audio_folder/valid/\n",
      "Counter di 22\n",
      "Error di file ./audio_folder/valid/common_voice_id_21192699.mp3\n",
      "Counter di 38\n",
      "Error di file ./audio_folder/valid/common_voice_id_26237570.mp3\n",
      "Counter di 77\n",
      "Error di file ./audio_folder/valid/common_voice_id_20847480.mp3\n",
      "Counter di 95\n",
      "Error di file ./audio_folder/valid/common_voice_id_35338065.mp3\n"
     ]
    }
   ],
   "source": [
    "dataset_train, df_train_filtered = PipelineTrain.load_audio()\n",
    "dataset_valid, df_valid_filtered = PipelineValid.load_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding(mfcc_tensor, index, n_mfcc=64, max_padding=512):\n",
    "    height, width = np.array(mfcc_tensor[index][0]).shape[0], np.array(mfcc_tensor[index][0]).shape[1]\n",
    "    \n",
    "    padded_mfcc = np.zeros([max_padding, n_mfcc])\n",
    "    padded_mfcc[:height, :width] = mfcc_tensor[index][0]\n",
    "    return padded_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_list = []\n",
    "for i in range(len(dataset_train)):\n",
    "    train_dataset_list.append(add_padding(dataset_train, i, max_padding=max_timestamps).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset_list = []\n",
    "for i in range(len(dataset_valid)):\n",
    "    valid_dataset_list.append(add_padding(dataset_valid, i, max_padding=max_timestamps).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_list = torch.tensor(train_dataset_list)\n",
    "valid_dataset_list = torch.tensor(valid_dataset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_x = train_dataset_list.to(device)\n",
    "valid_x = valid_dataset_list.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>common_voice_id_25248257.mp3</td>\n",
       "      <td>pak kimura menunjukkan foto kepada saya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>common_voice_id_35744791.mp3</td>\n",
       "      <td>kalian bersenang senang bukan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>common_voice_id_25407923.mp3</td>\n",
       "      <td>ibu saya lahir pada tanggal dua puluh sembilan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>common_voice_id_35627850.mp3</td>\n",
       "      <td>di amerika utara usaha umumnya berpegang pada ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>common_voice_id_33453481.mp3</td>\n",
       "      <td>tas itu besar dan berat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           path  \\\n",
       "0  common_voice_id_25248257.mp3   \n",
       "1  common_voice_id_35744791.mp3   \n",
       "2  common_voice_id_25407923.mp3   \n",
       "3  common_voice_id_35627850.mp3   \n",
       "4  common_voice_id_33453481.mp3   \n",
       "\n",
       "                                            sentence  \n",
       "0            pak kimura menunjukkan foto kepada saya  \n",
       "1                      kalian bersenang senang bukan  \n",
       "2  ibu saya lahir pada tanggal dua puluh sembilan...  \n",
       "3  di amerika utara usaha umumnya berpegang pada ...  \n",
       "4                            tas itu besar dan berat  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y, valid_y = [], []\n",
    "\n",
    "for text in df_train_filtered['sentence']:\n",
    "    train_y.append(conv_char2num(text))\n",
    "\n",
    "for text in df_valid_filtered['sentence']:\n",
    "    valid_y.append(conv_char2num(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = torch.tensor(train_y)\n",
    "valid_y = torch.tensor(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class myDataset(Dataset):\n",
    "    def __init__(self, data, transcriptions):\n",
    "        self.data = data\n",
    "        self.transcriptions = transcriptions\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        mfcc_matrix = self.data[index]\n",
    "        transcription = self.transcriptions[index]\n",
    "        return mfcc_matrix, transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_train_dataset = myDataset(train_x, train_y)\n",
    "my_valid_dataset = myDataset(valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_set = DataLoader(my_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_set = DataLoader(my_valid_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Initialize Model and Start Training</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Avg Loss: 3.2326\n",
      "Validation Loss: 3.0290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kevin Putra Santoso\\anaconda3\\envs\\avalon_pytorch\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Avg Loss: 2.9968\n",
      "Validation Loss: 2.8091\n",
      "Epoch [3/100], Avg Loss: 2.7899\n",
      "Validation Loss: 2.6137\n",
      "Epoch [4/100], Avg Loss: 2.6124\n",
      "Validation Loss: 2.4470\n",
      "Epoch [5/100], Avg Loss: 2.4621\n",
      "Validation Loss: 2.3119\n",
      "Epoch [6/100], Avg Loss: 2.3327\n",
      "Validation Loss: 2.1944\n",
      "Epoch [7/100], Avg Loss: 2.2227\n",
      "Validation Loss: 2.0944\n",
      "Epoch [8/100], Avg Loss: 2.1251\n",
      "Validation Loss: 2.0001\n",
      "Epoch [9/100], Avg Loss: 2.0394\n",
      "Validation Loss: 1.9222\n",
      "Epoch [10/100], Avg Loss: 1.9641\n",
      "Validation Loss: 1.8594\n",
      "Epoch [11/100], Avg Loss: 1.8962\n",
      "Validation Loss: 1.8280\n",
      "Epoch [12/100], Avg Loss: 1.8363\n",
      "Validation Loss: 1.7464\n",
      "Epoch [13/100], Avg Loss: 1.7823\n",
      "Validation Loss: 1.7141\n",
      "Epoch [14/100], Avg Loss: 1.7361\n",
      "Validation Loss: 1.6613\n",
      "Epoch [15/100], Avg Loss: 1.6949\n",
      "Validation Loss: 1.6274\n",
      "Epoch [16/100], Avg Loss: 1.6579\n",
      "Validation Loss: 1.6162\n",
      "Epoch [17/100], Avg Loss: 1.6231\n",
      "Validation Loss: 1.5716\n",
      "Epoch [18/100], Avg Loss: 1.5942\n",
      "Validation Loss: 1.5671\n",
      "Epoch [19/100], Avg Loss: 1.5665\n",
      "Validation Loss: 1.5398\n",
      "Epoch [20/100], Avg Loss: 1.5424\n",
      "Validation Loss: 1.5091\n",
      "Epoch [21/100], Avg Loss: 1.5215\n",
      "Validation Loss: 1.5113\n",
      "Epoch [22/100], Avg Loss: 1.5008\n",
      "Validation Loss: 1.4816\n",
      "Epoch [23/100], Avg Loss: 1.4837\n",
      "Validation Loss: 1.4892\n",
      "Epoch [24/100], Avg Loss: 1.4669\n",
      "Validation Loss: 1.4717\n",
      "Epoch [25/100], Avg Loss: 1.4521\n",
      "Validation Loss: 1.4637\n",
      "Epoch [26/100], Avg Loss: 1.4384\n",
      "Validation Loss: 1.4525\n",
      "Epoch [27/100], Avg Loss: 1.4262\n",
      "Validation Loss: 1.4557\n",
      "Epoch [28/100], Avg Loss: 1.4151\n",
      "Validation Loss: 1.4290\n",
      "Epoch [29/100], Avg Loss: 1.4041\n",
      "Validation Loss: 1.4094\n",
      "Epoch [30/100], Avg Loss: 1.3950\n",
      "Validation Loss: 1.4321\n",
      "Epoch [31/100], Avg Loss: 1.3855\n",
      "Validation Loss: 1.4248\n",
      "Epoch [32/100], Avg Loss: 1.3774\n",
      "Validation Loss: 1.4121\n",
      "Epoch [33/100], Avg Loss: 1.3691\n",
      "Validation Loss: 1.4126\n",
      "Epoch [34/100], Avg Loss: 1.3619\n",
      "Validation Loss: 1.4029\n",
      "Epoch [35/100], Avg Loss: 1.3553\n",
      "Validation Loss: 1.3876\n",
      "Epoch [36/100], Avg Loss: 1.3484\n",
      "Validation Loss: 1.3697\n",
      "Epoch [37/100], Avg Loss: 1.3419\n",
      "Validation Loss: 1.3898\n",
      "Epoch [38/100], Avg Loss: 1.3362\n",
      "Validation Loss: 1.3927\n",
      "Epoch [39/100], Avg Loss: 1.3307\n",
      "Validation Loss: 1.3649\n",
      "Epoch [40/100], Avg Loss: 1.3253\n",
      "Validation Loss: 1.3840\n",
      "Epoch [41/100], Avg Loss: 1.3197\n",
      "Validation Loss: 1.3455\n",
      "Epoch [42/100], Avg Loss: 1.3158\n",
      "Validation Loss: 1.3713\n",
      "Epoch [43/100], Avg Loss: 1.3111\n",
      "Validation Loss: 1.3698\n",
      "Epoch [44/100], Avg Loss: 1.3055\n",
      "Validation Loss: 1.3619\n",
      "Epoch [45/100], Avg Loss: 1.3019\n",
      "Validation Loss: 1.3528\n",
      "Epoch [46/100], Avg Loss: 1.2969\n",
      "Validation Loss: 1.3667\n",
      "Epoch [47/100], Avg Loss: 1.2926\n",
      "Validation Loss: 1.3574\n",
      "Epoch [48/100], Avg Loss: 1.2885\n",
      "Validation Loss: 1.3460\n",
      "Epoch [49/100], Avg Loss: 1.2848\n",
      "Validation Loss: 1.3185\n",
      "Epoch [50/100], Avg Loss: 1.2803\n",
      "Validation Loss: 1.3354\n",
      "Epoch [51/100], Avg Loss: 1.2766\n",
      "Validation Loss: 1.3204\n",
      "Epoch [52/100], Avg Loss: 1.2728\n",
      "Validation Loss: 1.3245\n",
      "Epoch [53/100], Avg Loss: 1.2688\n",
      "Validation Loss: 1.3128\n",
      "Epoch [54/100], Avg Loss: 1.2642\n",
      "Validation Loss: 1.3050\n",
      "Epoch [55/100], Avg Loss: 1.2609\n",
      "Validation Loss: 1.3275\n",
      "Epoch [56/100], Avg Loss: 1.2566\n",
      "Validation Loss: 1.3042\n",
      "Epoch [57/100], Avg Loss: 1.2531\n",
      "Validation Loss: 1.3352\n",
      "Epoch [58/100], Avg Loss: 1.2500\n",
      "Validation Loss: 1.2760\n",
      "Epoch [59/100], Avg Loss: 1.2449\n",
      "Validation Loss: 1.3040\n",
      "Epoch [60/100], Avg Loss: 1.2416\n",
      "Validation Loss: 1.2852\n",
      "Epoch [61/100], Avg Loss: 1.2376\n",
      "Validation Loss: 1.2877\n",
      "Epoch [62/100], Avg Loss: 1.2339\n",
      "Validation Loss: 1.2947\n",
      "Epoch [63/100], Avg Loss: 1.2295\n",
      "Validation Loss: 1.2840\n",
      "Epoch [64/100], Avg Loss: 1.2256\n",
      "Validation Loss: 1.2865\n",
      "Epoch [65/100], Avg Loss: 1.2220\n",
      "Validation Loss: 1.2581\n",
      "Epoch [66/100], Avg Loss: 1.2171\n",
      "Validation Loss: 1.2612\n",
      "Epoch [67/100], Avg Loss: 1.2140\n",
      "Validation Loss: 1.2696\n",
      "Epoch [68/100], Avg Loss: 1.2100\n",
      "Validation Loss: 1.2497\n",
      "Epoch [69/100], Avg Loss: 1.2060\n",
      "Validation Loss: 1.2580\n",
      "Epoch [70/100], Avg Loss: 1.2024\n",
      "Validation Loss: 1.2406\n",
      "Epoch [71/100], Avg Loss: 1.1972\n",
      "Validation Loss: 1.2509\n",
      "Epoch [72/100], Avg Loss: 1.1940\n",
      "Validation Loss: 1.2489\n",
      "Epoch [73/100], Avg Loss: 1.1890\n",
      "Validation Loss: 1.2205\n",
      "Epoch [74/100], Avg Loss: 1.1853\n",
      "Validation Loss: 1.2560\n",
      "Epoch [75/100], Avg Loss: 1.1808\n",
      "Validation Loss: 1.2163\n",
      "Epoch [76/100], Avg Loss: 1.1777\n",
      "Validation Loss: 1.2353\n",
      "Epoch [77/100], Avg Loss: 1.1732\n",
      "Validation Loss: 1.2146\n",
      "Epoch [78/100], Avg Loss: 1.1690\n",
      "Validation Loss: 1.2034\n",
      "Epoch [79/100], Avg Loss: 1.1650\n",
      "Validation Loss: 1.2009\n",
      "Epoch [80/100], Avg Loss: 1.1605\n",
      "Validation Loss: 1.2140\n",
      "Epoch [81/100], Avg Loss: 1.1568\n",
      "Validation Loss: 1.1870\n",
      "Epoch [82/100], Avg Loss: 1.1522\n",
      "Validation Loss: 1.1881\n",
      "Epoch [83/100], Avg Loss: 1.1483\n",
      "Validation Loss: 1.1940\n",
      "Epoch [84/100], Avg Loss: 1.1434\n",
      "Validation Loss: 1.1850\n",
      "Epoch [85/100], Avg Loss: 1.1393\n",
      "Validation Loss: 1.1719\n",
      "Epoch [86/100], Avg Loss: 1.1354\n",
      "Validation Loss: 1.1705\n",
      "Epoch [87/100], Avg Loss: 1.1312\n",
      "Validation Loss: 1.1735\n",
      "Epoch [88/100], Avg Loss: 1.1275\n",
      "Validation Loss: 1.1696\n",
      "Epoch [89/100], Avg Loss: 1.1233\n",
      "Validation Loss: 1.1638\n",
      "Epoch [90/100], Avg Loss: 1.1189\n",
      "Validation Loss: 1.1544\n",
      "Epoch [91/100], Avg Loss: 1.1152\n",
      "Validation Loss: 1.1616\n",
      "Epoch [92/100], Avg Loss: 1.1118\n",
      "Validation Loss: 1.1630\n",
      "Epoch [93/100], Avg Loss: 1.1075\n",
      "Validation Loss: 1.1449\n",
      "Epoch [94/100], Avg Loss: 1.1044\n",
      "Validation Loss: 1.1546\n",
      "Epoch [95/100], Avg Loss: 1.1010\n",
      "Validation Loss: 1.1435\n",
      "Epoch [96/100], Avg Loss: 1.0986\n",
      "Validation Loss: 1.1392\n",
      "Epoch [97/100], Avg Loss: 1.0948\n",
      "Validation Loss: 1.1481\n",
      "Epoch [98/100], Avg Loss: 1.0919\n",
      "Validation Loss: 1.1256\n",
      "Epoch [99/100], Avg Loss: 1.0887\n",
      "Validation Loss: 1.1290\n",
      "Epoch [100/100], Avg Loss: 1.0858\n",
      "Validation Loss: 1.1371\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model = Transformer().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "def train_step(model, optimizer, batch):\n",
    "    source = batch[0]\n",
    "    target = batch[1]\n",
    "    dec_input = target[:, :-1]\n",
    "    dec_target = target[:, 1:]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    preds = model([source, dec_input])\n",
    "\n",
    "    one_hot = F.one_hot(dec_target.long(), num_classes=model.num_classes).float()\n",
    "    one_hot = one_hot.permute(0, 2, 1)\n",
    "    mask = dec_target != 0\n",
    "    mask = mask.float()\n",
    "    \n",
    "    loss = F.cross_entropy(preds.transpose(1, 2), one_hot.to(device), label_smoothing=0.1)\n",
    "    loss = (loss * mask.to(device)).sum() / mask.sum()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return {\"Loss\": loss.item()}\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_set:\n",
    "            source = batch[0]\n",
    "            target = batch[1]\n",
    "            dec_input = target[:, :-1]\n",
    "            dec_target = target[:, 1:]\n",
    "            preds = model((source, dec_input))\n",
    "            one_hot_tgt = F.one_hot(dec_target.long(), num_classes=model.num_classes).float().permute(0, 2, 1).to(device)\n",
    "\n",
    "            mask = batch_tgt != 0\n",
    "            mask = mask.float()\n",
    "            loss = F.cross_entropy(preds.transpose(1, 2), one_hot_tgt,label_smoothing=0.1)\n",
    "            loss = (loss * mask.to(device)).sum() / mask.sum()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(valid_set)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for batch_src, batch_tgt in train_set:\n",
    "        loss = train_step(model, optimizer, [batch_src, batch_tgt])\n",
    "        epoch_loss += loss['Loss']\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / len(train_set)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Avg Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "    validation_loss = validate()\n",
    "    print(f\"Validation Loss: {validation_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
